{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "573e4117bb661cb7749a715467977bb6",
     "grade": false,
     "grade_id": "cell-markdown-task",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Exercise 2 - Bigram Matrix\n",
    "(6 points)\n",
    "\n",
    "You should finish the implementation of the given `BigramMatrix` class. Its constructor takes a list of tokens (the same tokens your `preprocess` method in the former exercise should create) to generate a count matrix of bi-grams.\n",
    "\n",
    "Let $c(w_i,w_j)$ be the number of bigrams $(w_i, w_j)$, i.e., the number of times the words $w_i$ stays in front of the word $w_j$. Your bigram matrix should contain a matrix of counts where `counts[i][j]` contains the value of $c(w_i,w_j)$.\n",
    "\n",
    "For the input tokens \n",
    "```\n",
    "[<s>, she, said, i, know, that, she, likes, english, food, </s>]\n",
    "```\n",
    "the matrix looks like the following table (rows are $w_i$ and columns are $w_j$)\n",
    "\n",
    "| $w_i$ \\ $w_j$ | `<s>` | `</s>` | `english` | `food` | `i` | `know` | `likes` | `said` | `she` | `that` |\n",
    "|---|---|---|---|---|---|---|---|---|---|---|\n",
    "| `<s>` | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 |\n",
    "| `</s>` | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n",
    "| `english` | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 |\n",
    "| `food` | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n",
    "| `i` | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 |\n",
    "| `know` | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 |\n",
    "| `likes` | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n",
    "| `said` | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 |\n",
    "| `she` | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 1 | 0 | 0 |\n",
    "| `that` | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 |\n",
    "\n",
    "* `create(List<String> tokens)` should initialize the matrix.\n",
    "* `normalize()` should normalize the counts of the matrix (note that a application of the Laplace smoothing should still be possible, even after normalizing).\n",
    "* `performLaplaceSmoothing()` should perform Laplace smoothing on the counts in the matrix (and on the normalized values of the matrix if it has been normalized before)\n",
    "* `getCount(String word1, String word2)` should return the (eventually smoothed) count for the bi-gram `(word1, word2)`.\n",
    "* `getNormalizedCount(String word1, String word2)` should return the (eventually smoothed,) normalized count for the bi-gram `(word1, word2)` (i.e., the probability $P(word2|word1)$).\n",
    "\n",
    "Additionally, you should try to handle unknown words (i.e., words which do not occur in the given text) in a meaningful way, by implementing the following rules:\n",
    "* If smoothing has not been applied and one of the words of a bi-gram is not known, return $0$.\n",
    "* If the matrix has been smoothed, word1 is know and word2 was not part of the given list of tokens, assume that it is a part of the matrix by returning $1$ for its count and $1/s$ as its normalization (where $s$ is the sum of the row of word1 (without adding the $1$ of word2 to this row)).\n",
    "* If the matrix has been smoothed and word1 was not part of the given list of tokens, assume that its row was empty before smoothing and contains only $1$s after smoothing.\n",
    "\n",
    "You implementation will be tested in 5 different scenarios:\n",
    "* The matrix is created and the pure counts are checked.\n",
    "* The matrix is normalized and the normalized counts are checked.\n",
    "* The matrix is smoothed and the smoothed counts are checked.\n",
    "* The matrix is normalized and smoothed and the normalized counts are checked.\n",
    "* In contrast to the 4 cases above, the matrix is checked with words that do not occur in the text (again in all 4 previous scenarios).\n",
    "\n",
    "#### Notes\n",
    "\n",
    "- You are free to use a different IDE to develop your solution. However, you have to copy the solution into this notebook to submit it.\n",
    "- Do not add additional external libraries.\n",
    "- Interface\n",
    "  - You can use _[TAB]_ for autocompletion and _[SHIFT]_+_[TAB]_ for code inspection.\n",
    "  - Use _Menu_ -> _View_ -> _Toggle Line Numbers_ for debugging.\n",
    "  - Check _Menu_ -> _Help_ -> _Keyboard Shortcuts_.\n",
    "- Known issues\n",
    "  - All global variables will be set to void after an import.\n",
    "  - Missing spaces arround `%` (Modulo) can cause unexpected errors so please make sure that you have added spaces around every `%` character.\n",
    "- Finish\n",
    "  - Save your solution by clicking on the _disk icon_.\n",
    "  - Make sure that all necessary imports are listed at the beginning of your cell.\n",
    "  - Run a final check of your solution by\n",
    "    - click on _restart the kernel, then re-run the whole notebook_ (the fast forward arrow in the tool bar)\n",
    "    - wait fo the kernel to restart and execute all cells (all executable cells should have numbers in front of them instead of a `[*]`) \n",
    "    - Check all executed cells for errors. If an exception is thrown, please check your code. Note that although the error might look cryptic, until now we never encounter that an exception was caused without a valid reason inside of the submitted code. A good way to check the code is to copy the solution into a new class in your favorite IDE and check\n",
    "      - errors reported by the IDE\n",
    "      - imports the IDE adds to your code which might be missing in your submission.\n",
    "  - Finally, choose _Menu_ -> _File_ -> _Close and Halt_.\n",
    "  - Do not forget to _Submit_ your solution in the _Assignments_ view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "73fc412c7dcae2fb13474994a5246e60",
     "grade": false,
     "grade_id": "cell-code",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import java.util.ArrayList;\n",
    "import java.util.Arrays;\n",
    "import java.util.HashMap;\n",
    "import java.util.List;\n",
    "import java.util.Map;\n",
    "\n",
    "public class BigramMatrix {\n",
    "\tint[][] matrix;\n",
    "\tdouble[][] normalisedMatrix;\n",
    "\tint[][] laplacedMatrix;\n",
    "\tboolean smooth;\n",
    "\tMap<String, Integer> unigramCount = new HashMap<>();\n",
    "\tList<String> uniqueTokens = new ArrayList<>();\n",
    "\n",
    "\tpublic BigramMatrix(List<String> tokens) {\n",
    "\t\tcreate(tokens);\n",
    "\t}\n",
    "\n",
    "\t// Do remember to add the missing word functionality\n",
    "\n",
    "\tpublic void create(List<String> token) {\n",
    "\n",
    "\t\t// This is the list of unique tokens in a list\n",
    "\t\tsmooth = false;\n",
    "\t\tfor (String findUnique : token) {\n",
    "\t\t\tif (!uniqueTokens.contains(findUnique)) {\n",
    "\t\t\t\tuniqueTokens.add(findUnique);\n",
    "\t\t\t}\n",
    "\t\t}\n",
    "\t\tcreateUnigram(token);\n",
    "\t\tmatrix = new int[uniqueTokens.size()][uniqueTokens.size()];\n",
    "\t\tnormalisedMatrix = new double[uniqueTokens.size()][uniqueTokens.size()];\n",
    "\n",
    "\t\tfor (int i = 0; i < token.size() - 1; i++) {\n",
    "\t\t\tString firstToken = token.get(i);\n",
    "\t\t\tint index = uniqueTokens.indexOf(firstToken);\n",
    "\t\t\tString laterToken = token.get(i + 1);\n",
    "\t\t\tint indexSecond = uniqueTokens.indexOf(laterToken);\n",
    "\t\t\tmatrix[index][indexSecond] += 1;\n",
    "\t\t}\n",
    "\n",
    "\t}\n",
    "\n",
    "\tpublic Map<String, Integer> createUnigram(List<String> token) {\n",
    "\n",
    "\t\tfor (String tokenTemp : token) {\n",
    "\t\t\tif (unigramCount.containsKey(tokenTemp)) {\n",
    "\t\t\t\tint count = unigramCount.get(tokenTemp);\n",
    "\t\t\t\tcount++;\n",
    "\t\t\t\tunigramCount.put(tokenTemp, count);\n",
    "\t\t\t} else {\n",
    "\t\t\t\tunigramCount.put(tokenTemp, 1);\n",
    "\t\t\t}\n",
    "\t\t}\n",
    "\t\treturn unigramCount;\n",
    "\t}\n",
    "\n",
    "\t/**\n",
    "\t * Returns the count of the bi-gram matrix for the bi-gram (word1, word2).\n",
    "\t */\n",
    "\tpublic double getCount(String word1, String word2) {\n",
    "\t\tdouble count = 0;\n",
    "        \n",
    "\t\t// YOUR CODE HERE\n",
    "\t\tif (smooth == false) {\n",
    "\t\t\tif (!uniqueTokens.contains(word1) || !uniqueTokens.contains(word2))\n",
    "\n",
    "\t\t\t\tcount = 0;\n",
    "\t\t\telse {\n",
    "\t\t\t\tint firstToken = uniqueTokens.indexOf(word1);\n",
    "\t\t\t\tint secondToken = uniqueTokens.indexOf(word2);\n",
    "\t\t\t\tcount = matrix[firstToken][secondToken];\n",
    "\t\t\t}\n",
    "\t\t}\n",
    "\n",
    "\t\telse {\n",
    "\t\t\tif (!uniqueTokens.contains(word2) || !uniqueTokens.contains(word1))\n",
    "\t\t\t\tcount = 1;\n",
    "\t\t\telse {\n",
    "\t\t\t\tint firstToken = uniqueTokens.indexOf(word1);\n",
    "\t\t\t\tint secondToken = uniqueTokens.indexOf(word2);\n",
    "\t\t\t\tcount = matrix[firstToken][secondToken];\n",
    "\t\t\t}\n",
    "\n",
    "\t\t}\n",
    "\t\t\n",
    "\t\treturn count;\n",
    "\t}\n",
    "\n",
    "\tpublic void assignMatrix(String word1, String word2, int count) {\n",
    "\t\tint firstToken = uniqueTokens.indexOf(word1);\n",
    "\t\tint secondToken = uniqueTokens.indexOf(word2);\n",
    "\t\tmatrix[firstToken][secondToken] = count;\n",
    "\t}\n",
    "\n",
    "\t/**\n",
    "\t * Transforms the internal count matrix into a normalized counts matrix.\n",
    "\t */\n",
    "\tpublic void normalize() {\n",
    "\t\t// YOUR CODE HERE\n",
    "\t\t// flag = true;\n",
    "\t\tfor (int i = 0; i < matrix.length; i++) {\n",
    "\t\t\tint sum = 0;\n",
    "\t\t\tfor (int j = 0; j < matrix.length; j++) {\n",
    "\t\t\t\tsum += matrix[i][j];\n",
    "\t\t\t}\n",
    "\t\t\tfor (int j = 0; j < matrix.length; j++) {\n",
    "\t\t\t\tif (sum != 0)\n",
    "\t\t\t\t\tnormalisedMatrix[i][j] = (double) matrix[i][j] / sum;\n",
    "\t\t\t}\n",
    "\t\t}\n",
    "\t}\n",
    "\n",
    "\t/**\n",
    "\t * Returns the normalized count of the bi-gram matrix for the bi-gram\n",
    "\t * (word1, word2) (i.e., P(word2 | word1)).\n",
    "\t */\n",
    "\tpublic double getNormalizedCount(String word1, String word2) {\n",
    "\t\tdouble normalizedCount = 0;\n",
    "        \n",
    "\t\t\n",
    "\t\t// YOUR CODE HERE\n",
    "\t\tint indexWord1 = 0;\n",
    "\t\tint indexWord2 = 0;\n",
    "\t\tif (smooth == false && (!uniqueTokens.contains(word1) || !uniqueTokens.contains(word2)))\n",
    "\t\t\tnormalizedCount = 0;\n",
    "\t\telse if (smooth == false) {\n",
    "\t\t\tindexWord1 = uniqueTokens.indexOf(word1);\n",
    "\t\t\tindexWord2 = uniqueTokens.indexOf(word2);\n",
    "\t\t\tnormalizedCount = normalisedMatrix[indexWord1][indexWord2];\n",
    "\t\t} else if (smooth == true) {\n",
    "\t\t\tif (!uniqueTokens.contains(word2) && uniqueTokens.contains(word1)) {\n",
    "\n",
    "\t\t\t\t// As we have to do 1/s, so we are calculating the sum of\n",
    "\t\t\t\t// word1's row.\n",
    "\t\t\t\tint[] word1Array = matrix[uniqueTokens.indexOf(word1)];\n",
    "\t\t\t\tint sum = 0;\n",
    "\t\t\t\tfor (int i : word1Array) {\n",
    "\t\t\t\t\tsum += i;\n",
    "\t\t\t\t}\n",
    "\t\t\t\t// as if word2 is not there, we assume it is there\n",
    "\t\t\t\tint laplacedCount = 1;\n",
    "\n",
    "\t\t\t\t// 1/c(wi)+V)\n",
    "\t\t\t\tnormalizedCount = (double) laplacedCount / (unigramCount.get(word1) + uniqueTokens.size());\n",
    "\t\t\t}\n",
    "\n",
    "\t\t\t// if word1 is not there\n",
    "\t\t\telse if (!uniqueTokens.contains(word1) && uniqueTokens.contains(word2)) {\n",
    "\t\t\t\t// as word1 is not present after smoothing, we will assume it is\n",
    "\t\t\t\t// 1 for its bigram vector.\n",
    "\t\t\t\tindexWord2 = uniqueTokens.indexOf(word2);\n",
    "\t\t\t\tint laplacedCount = 1;\n",
    "\t\t\t\tnormalizedCount = (double) laplacedCount / (uniqueTokens.size());\n",
    "\t\t\t}\n",
    "\n",
    "\t\t\telse if (uniqueTokens.contains(word1) && uniqueTokens.contains(word2)) {\n",
    "\n",
    "\t\t\t\tindexWord1 = uniqueTokens.indexOf(word1);\n",
    "\t\t\t\tindexWord2 = uniqueTokens.indexOf(word2);\n",
    "\t\t\t\tint laplacedCount = matrix[indexWord1][indexWord2];\n",
    "\t\t\t\tnormalizedCount = (double) laplacedCount / (unigramCount.get(word1) + uniqueTokens.size());\n",
    "\t\t\t}\n",
    "\n",
    "\t\t\telse {\n",
    "\t\t\t\t// here both words are unknown. So we do the word2 unknown thing\n",
    "\t\t\t\tnormalizedCount = (double) 1 / matrix.length;\n",
    "\t\t\t}\n",
    "\n",
    "\t\t}\n",
    "\t\treturn normalizedCount;\n",
    "\n",
    "\t}\n",
    "\n",
    "\tpublic void performLaplaceSmoothing() {\n",
    "\t\t// YOUR CODE HERE\n",
    "\t\t// Map<String, Integer> mapCount = createUnigram(list);\n",
    "\t\tfor (int i = 0; i < uniqueTokens.size(); i++) {\n",
    "\t\t\tfor (int j = 0; j < uniqueTokens.size(); j++) {\n",
    "\n",
    "\t\t\t\tString secondToken = uniqueTokens.get(j);\n",
    "\t\t\t\tString firstToken = uniqueTokens.get(i);\n",
    "\n",
    "\t\t\t\t// c(wi-1,wi)\n",
    "\t\t\t\tdouble secondCount = getCount(firstToken, secondToken);\n",
    "\n",
    "\t\t\t\t// Laplace: add -1\n",
    "\t\t\t\tassignMatrix(firstToken, secondToken, (int) secondCount + 1);\n",
    "\n",
    "\t\t\t}\n",
    "\t\t}\n",
    "\n",
    "\t\t// switch the smooth flag to denote that smoothing has been completed.\n",
    "\t\tsmooth = true;\n",
    "\n",
    "\t}\n",
    "\n",
    "}\n",
    "\n",
    "// This line should make sure that compile errors are directly identified when executing this cell\n",
    "// (the line itself does not produce any meaningful result)\n",
    "(new BigramMatrix(Arrays.asList(\"a\", \"b\"))).normalize();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4e9c819c081918a6fde3b4ba21898440",
     "grade": false,
     "grade_id": "cell-markdown-evaluation",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Evaluation\n",
    "\n",
    "- Run the following cell to test your implementation.\n",
    "- You can ignore the cells afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eff13554f500c13f126f7a27a3248331",
     "grade": true,
     "grade_id": "cell-autograde-visible",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- 1st example -----\n",
      "Check counts: Test(s) successfully completed.\n",
      "Check normalized counts: Test(s) successfully completed.\n",
      "Check smoothed counts: Test(s) successfully completed.\n",
      "Check normalized, smoothed counts: Test(s) successfully completed.\n",
      "----- 2nd example -----\n",
      "Check counts: Test(s) successfully completed.\n",
      "Check normalized counts: Test(s) successfully completed.\n",
      "Check smoothed counts: Test(s) successfully completed.\n",
      "Check normalized, smoothed counts: Test(s) successfully completed.\n",
      "----- Test with unknown words -----\n",
      "Check counts: Test(s) successfully completed.\n",
      "Check normalized counts: Test(s) successfully completed.\n",
      "Check smoothed counts: Test(s) successfully completed.\n",
      "Check normalized, smoothed counts: Test(s) successfully completed.\n"
     ]
    }
   ],
   "source": [
    "%maven org.junit.jupiter:junit-jupiter-api:5.3.1\n",
    "import org.junit.jupiter.api.Assertions;\n",
    "import org.opentest4j.AssertionFailedError;\n",
    "\n",
    "public static final double DELTA = 0.000001;\n",
    "\n",
    "public static void checkMatrix(BigramMatrix matrix, String[][] testCases, double[] expectedValues,\n",
    "        boolean checkNormalizedCounts) throws Exception {\n",
    "    try {\n",
    "        double value, diff;\n",
    "        for (int i = 0; i < testCases.length; i++) {\n",
    "            value = checkNormalizedCounts ? matrix.getNormalizedCount(testCases[i][0], testCases[i][1])\n",
    "                    : matrix.getCount(testCases[i][0], testCases[i][1]);\n",
    "            diff = Math.abs(value - expectedValues[i]);\n",
    "            Assertions.assertTrue(diff < DELTA, \"Your solution returned \"\n",
    "                    + (checkNormalizedCounts ? (\"P(\\\"\" + testCases[i][1] + \"\\\"|\\\"\" + testCases[i][0] + \"\\\")=\")\n",
    "                            : (\"c(\\\"\" + testCases[i][0] + \"\\\",\\\"\" + testCases[i][1] + \"\\\")=\"))\n",
    "                    + value + \" while \" + expectedValues[i] + \" has been expected.\");\n",
    "        }\n",
    "        System.out.println(\"Test(s) successfully completed.\");\n",
    "    } catch (AssertionFailedError e) {\n",
    "        throw e;\n",
    "    } catch (RuntimeException e) {\n",
    "        System.err.println(\"Your solution caused an unexpected error:\");\n",
    "        throw e;\n",
    "    }\n",
    "}\n",
    "\n",
    "System.out.println(\"----- 1st example -----\");\n",
    "List<String> tokens = Arrays.asList(\"<s>\", \"she\", \"said\", \"i\", \"know\", \"that\", \"she\", \"likes\",\n",
    "                                        \"english\", \"food\", \"</s>\");\n",
    "BigramMatrix m = new BigramMatrix(tokens);\n",
    "\n",
    "System.out.print(\"Check counts: \");\n",
    "checkMatrix(m,\n",
    "        new String[][] { { \"she\", \"said\" }, { \"english\", \"food\" }, { \"likes\", \"food\" } },\n",
    "        new double[] { 1, 1, 0 }, false);\n",
    "\n",
    "m.normalize();\n",
    "System.out.print(\"Check normalized counts: \");\n",
    "checkMatrix(m,\n",
    "        new String[][] { { \"she\", \"said\" }, { \"english\", \"food\" }, { \"likes\", \"food\" } },\n",
    "        new double[] { 0.5, 1, 0 }, true);\n",
    "\n",
    "m.performLaplaceSmoothing();\n",
    "System.out.print(\"Check smoothed counts: \");\n",
    "checkMatrix(m,\n",
    "        new String[][] { { \"she\", \"said\" }, { \"english\", \"food\" }, { \"likes\", \"food\" } },\n",
    "        new double[] { 2, 2, 1 }, false);\n",
    "\n",
    "System.out.print(\"Check normalized, smoothed counts: \");\n",
    "checkMatrix(m,\n",
    "        new String[][] { { \"she\", \"said\" }, { \"english\", \"food\" }, { \"likes\", \"food\" } },\n",
    "        new double[] { 1.0 / 6.0, 2.0 / 11.0, 1.0 / 11.0 }, true);\n",
    "\n",
    "System.out.println(\"----- 2nd example -----\");\n",
    "// Apply the solution to a longer example\n",
    "tokens = Arrays.asList(\"<s>\", \"london\", \"is\", \"the\", \"capital\", \"and\", \"largest\", \"city\", \"of\",\n",
    "                      \"england\", \"</s>\", \"<s>\", \"million\", \"people\", \"live\", \"in\", \"london\",\n",
    "                      \"</s>\", \"<s>\", \"the\", \"river\", \"thames\", \"is\", \"in\", \"london\", \"</s>\",\n",
    "                      \"<s>\", \"london\", \"is\", \"the\", \"largest\", \"city\", \"in\", \"western\",\n",
    "                      \"europe\", \"</s>\");\n",
    "m = new BigramMatrix(tokens);\n",
    "\n",
    "System.out.print(\"Check counts: \");\n",
    "checkMatrix(m, new String[][] { { \"london\", \"</s>\" }, { \"largest\", \"city\" }, { \"river\", \"thames\" },\n",
    "        { \"city\", \"river\" } }, new double[] { 2, 2, 1, 0 }, false);\n",
    "\n",
    "m.normalize();\n",
    "System.out.print(\"Check normalized counts: \");\n",
    "checkMatrix(m, new String[][] { { \"london\", \"</s>\" }, { \"largest\", \"city\" }, { \"river\", \"thames\" },\n",
    "        { \"city\", \"river\" } }, new double[] { 0.5, 1.0, 1.0, 0 }, true);\n",
    "\n",
    "m.performLaplaceSmoothing();\n",
    "System.out.print(\"Check smoothed counts: \");\n",
    "checkMatrix(m, new String[][] { { \"london\", \"</s>\" }, { \"largest\", \"city\" }, { \"river\", \"thames\" },\n",
    "        { \"city\", \"river\" } }, new double[] { 3, 3, 2, 1 }, false);\n",
    "\n",
    "System.out.print(\"Check normalized, smoothed counts: \");\n",
    "checkMatrix(m, new String[][] { { \"london\", \"</s>\" }, { \"largest\", \"city\" }, { \"river\", \"thames\" },\n",
    "        { \"city\", \"river\" } }, new double[] { 3.0 / 23.0, 1.0 / 7.0 , 0.1, 1.0 / 21 }, true);\n",
    "\n",
    "System.out.println(\"----- Test with unknown words -----\");\n",
    "m = new BigramMatrix(tokens); // set matrix back\n",
    "// Check unknown words\n",
    "System.out.print(\"Check counts: \");\n",
    "checkMatrix(m, new String[][] { { \"london\", \"underground\" }, { \"small\", \"city\" }, { \"sky\", \"scraper\" } }, \n",
    "            new double[] { 0, 0, 0 }, false);\n",
    "\n",
    "m.normalize();\n",
    "System.out.print(\"Check normalized counts: \");\n",
    "checkMatrix(m, new String[][] { { \"london\", \"underground\" }, { \"small\", \"city\" }, { \"sky\", \"scraper\" } }, \n",
    "            new double[] { 0, 0, 0 }, true);\n",
    "\n",
    "m.performLaplaceSmoothing();\n",
    "System.out.print(\"Check smoothed counts: \");\n",
    "checkMatrix(m, new String[][] { { \"london\", \"underground\" }, { \"small\", \"city\" }, { \"sky\", \"scraper\" } }, \n",
    "            new double[] { 1, 1, 1 }, false);\n",
    "\n",
    "System.out.print(\"Check normalized, smoothed counts: \");\n",
    "checkMatrix(m, new String[][] { { \"london\", \"underground\" }, { \"small\", \"city\" }, { \"sky\", \"scraper\" } }, \n",
    "            new double[] { 1.0 / 23.0, 1.0 / 19.0, 1.0 / 19.0 }, true);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8a3c775cba39765e86387d52378f4b40",
     "grade": true,
     "grade_id": "cell-autograde-1",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "// Ignore this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "524647178811e51573f60ce2158d7f95",
     "grade": true,
     "grade_id": "cell-autograde-2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "// Ignore this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5161a1a7e26d3c55639306ebbfcdc765",
     "grade": true,
     "grade_id": "cell-autograde-3",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "// Ignore this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6ed525019b34cc2f5c6dc79bafcc8247",
     "grade": true,
     "grade_id": "cell-autograde-4",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "// Ignore this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a4a7b22086ea145ad6648539f9ca96fc",
     "grade": true,
     "grade_id": "cell-autograde-5",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "// Ignore this cell"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Java",
   "language": "java",
   "name": "java"
  },
  "language_info": {
   "codemirror_mode": "java",
   "file_extension": ".jshell",
   "mimetype": "text/x-java-source",
   "name": "Java",
   "pygments_lexer": "java",
   "version": "11.0.4+11-post-Ubuntu-1ubuntu218.04.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
