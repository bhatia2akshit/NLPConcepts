{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b9195de0b7a4e944632a2059ee530d84",
     "grade": false,
     "grade_id": "cell-markdown-task",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Exercise 1 â€“ Naive Bayes Classification\n",
    "(10 points)\n",
    "\n",
    "Implement a Naive Bayes classifier by finalizing the two given classes. The `BayesianLearner` class acts like a builder for the `BayesianClassifier` instances. That means that the learner gets the set of classes during its creation and the `learnExample` method of the learner is called once for each document of the training set. Internally, the learner should gather all statistics that are necessary for the classifier when processing the training examples.\n",
    "After the learner saw all training documents, the `createClassifier` method is called which creates an instance of the `BayesianClassifier` class and initializes it with the statistics gathered before. \n",
    "The classification itself is carried out by the `classify` method which takes an unknown document and assigns it one of the classes learned before.\n",
    "\n",
    "#### Hints\n",
    "\n",
    "- Please do not forget to preprocess your documents. What exactly the preprocessing does is up to you.\n",
    "- The evaluation will measure the accuracy of your classifier.\n",
    "- The evaluation in the hidden tests has three stages. \n",
    "  1. Your solution will get 4 points as soon as it is better than the baselines. The baselines are:\n",
    "     - For each class, a classifier that always returns this class.\n",
    "     - A random guesser that returns a random class.\n",
    "  2. If your solution has an accuracy >= 0.7, you will get 3 more points.\n",
    "  3. If your solution has an accuracy >= 0.8, you will get 3 more points.\n",
    "- You can download the [single-class-train.tsv](https://hobbitdata.informatik.uni-leipzig.de/teaching/SNLP/classification/single-class-train.tsv) file. It comprises one document per line. The first word is the class, followed by a tab character (`\\t`). The remaining content of the line is the text of the document.\n",
    "\n",
    "#### Notes\n",
    "\n",
    "- You are free to use a different IDE to develop your solution. However, you have to copy the solution into this notebook to submit it.\n",
    "- Do not add additional external libraries.\n",
    "- Interface\n",
    "  - You can use _[TAB]_ for autocompletion and _[SHIFT]_+_[TAB]_ for code inspection.\n",
    "  - Use _Menu_ -> _View_ -> _Toggle Line Numbers_ for debugging.\n",
    "  - Check _Menu_ -> _Help_ -> _Keyboard Shortcuts_.\n",
    "- Known issues\n",
    "  - All global variables will be set to void after an import.\n",
    "  - Missing spaces arround `%` (Modulo) can cause unexpected errors so please make sure that you have added spaces around every `%` character.\n",
    "- Finish\n",
    "  - Save your solution by clicking on the _disk icon_.\n",
    "  - Make sure that all necessary imports are listed at the beginning of your cell.\n",
    "  - Run a final check of your solution by\n",
    "    - click on _restart the kernel, then re-run the whole notebook_ (the fast forward arrow in the tool bar)\n",
    "    - wait fo the kernel to restart and execute all cells (all executable cells should have numbers in front of them instead of a `[*]`) \n",
    "    - Check all executed cells for errors. If an exception is thrown, please check your code. Note that although the error might look cryptic, until now we never encounter that an exception was caused without a valid reason inside of the submitted code. A good way to check the code is to copy the solution into a new class in your favorite IDE and check\n",
    "      - errors reported by the IDE\n",
    "      - imports the IDE adds to your code which might be missing in your submission.\n",
    "  - Finally, choose _Menu_ -> _File_ -> _Close and Halt_.\n",
    "  - Do not forget to _Submit_ your solution in the _Assignments_ view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a390e585964cf26b40c74f81cf74bc3e",
     "grade": false,
     "grade_id": "cell-code",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compiled\n"
     ]
    }
   ],
   "source": [
    "// package NaiveBayesian;\n",
    "import java.util.ArrayList;\n",
    "import java.util.Arrays;\n",
    "import java.util.HashMap;\n",
    "import java.util.List;\n",
    "import java.util.Map;\n",
    "import java.util.Set;\n",
    "\n",
    "// YOUR CODE HERE\n",
    "\n",
    "/**\n",
    " * Classifier implementing naive Bayes classification.\n",
    " */\n",
    "public class BayesianClassifier {\n",
    "\t// YOUR CODE HERE\n",
    "\tList<String> vocab;\n",
    "\tint N_docs = 0;\n",
    "\tList<Integer> Nclass;\n",
    "\tdouble[] priorProbs;\n",
    "\tMap<String, int[]> tokenFreqMap;\n",
    "\tList<String> classList;\n",
    "\tMap<String, Integer> docSize;\n",
    "\n",
    "\tBayesianClassifier(List<String> vocab, int N_docs, List<Integer> Nclass, Map<String, int[]> tokenFreqMap,\n",
    "\t\t\tList<String> classList, Map<String, Integer> docSize) {\n",
    "\t\tthis.vocab = vocab;\n",
    "\t\tthis.N_docs = N_docs;\n",
    "\t\tthis.Nclass = Nclass;\n",
    "\t\tthis.tokenFreqMap = tokenFreqMap;\n",
    "\t\tthis.classList = classList;\n",
    "\t\tthis.docSize = docSize;\n",
    "\t\t// This method will store probabilities in the map.\n",
    "\n",
    "\t\tpriorProbs = new double[Nclass.size()];\n",
    "\n",
    "\t\tfor (int i = 0; i < priorProbs.length; i++) {\n",
    "\t\t\tpriorProbs[i] = (double) Nclass.get(i) / N_docs;\n",
    "\t\t}\n",
    "\n",
    "\t}\n",
    "\n",
    "\tString[] stopwords = { \"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\",\n",
    "\t\t\t\"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\",\n",
    "\t\t\t\"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\",\n",
    "\t\t\t\"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\",\n",
    "\t\t\t\"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\",\n",
    "\t\t\t\"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\",\n",
    "\t\t\t\"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\",\n",
    "\t\t\t\"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\",\n",
    "\t\t\t\"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\",\n",
    "\t\t\t\"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\" };\n",
    "\n",
    "\tList<String> stopWordsList = Arrays.asList(stopwords);\n",
    "\n",
    "\tpublic String preprocessing(String text) {\n",
    "\t\tdouble[][] condProbArray = new double[vocab.size()][classList.size()];\n",
    "\n",
    "\t\tString[] tokens = text.toLowerCase().replaceAll(\"[^ a-zA-Z0-9]\", \"\").split(\" \");\n",
    "\t\tdouble score[] = new double[classList.size()];\n",
    "\t\t\n",
    "\t\tfor (String token : tokens) {\n",
    "\n",
    "\t\t\t// check if the token is not a stop word\n",
    "\t\t\tif (!stopWordsList.contains(token)) {\n",
    "\t\t\t\t// condiProb for that token:\n",
    "\t\t\t\t// freq(token,class:C)/freq(length(text:class:c)\n",
    "\t\t\t\tint indexToken = 0, freqToken = 0;\n",
    "\t\t\t\tboolean flag = false;\n",
    "\n",
    "\t\t\t\t// calculate the index if the token is in vocab\n",
    "\t\t\t\tif (vocab.contains(token)) {\n",
    "\t\t\t\t\tindexToken = vocab.indexOf(token);\n",
    "\t\t\t\t\tflag = true; // that token is in vocab\n",
    "\t\t\t\t}\n",
    "\t\t\t\tdouble condProb = 0.0;\n",
    "\n",
    "\t\t\t\tint i = 0;\n",
    "\t\t\t\t// calculate the score of each class for this token.\n",
    "\t\t\t\tfor (String c : classList) {\n",
    "\t\t\t\t\tint size = docSize.get(c);\n",
    "\t\t\t\t\tint[] wordList = tokenFreqMap.get(c);\n",
    "\t\t\t\t\t/*if(docSizeClass[i] == 0){\n",
    "\t\t\t\t\t\tint sum=0;\n",
    "\t\t\t\t\t\tfor(int j=0;j<wordList.length;j++){\n",
    "\t\t\t\t\t\t\t sum += wordList[i];\n",
    "\t\t\t\t\t\t}\n",
    "\t\t\t\t\t\tdocSizeClass[i]=sum;\n",
    "\t\t\t\t\t}*/\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\tdouble logToken;\n",
    "\n",
    "\t\t\t\t\tif (flag) {\n",
    "\n",
    "\t\t\t\t\t\tcondProb = condProbArray[indexToken][classList.indexOf(c)];\n",
    "\t\t\t\t\t\tif (condProb > 0) {\n",
    "\t\t\t\t\t\t\t// as the condprob is already there, calculate its\n",
    "\t\t\t\t\t\t\t// log\n",
    "\t\t\t\t\t\t\tlogToken = Math.log(condProb);\n",
    "\t\t\t\t\t\t\tscore[i] += logToken;\n",
    "\t\t\t\t\t\t\ti++;\n",
    "\t\t\t\t\t\t\tcontinue;\n",
    "\t\t\t\t\t\t}\n",
    "\t\t\t\t\t\t// if the condProb is not there, calculate\n",
    "\t\t\t\t\t\telse {\n",
    "\t\t\t\t\t\t\t// our aim here is to calculate only the freqToken\n",
    "\t\t\t\t\t\t\t// so it can be zero if the token is not in vocab.\n",
    "\t\t\t\t\t\t\tfreqToken = wordList[indexToken];\n",
    "\t\t\t\t\t\t\tcondProbArray[indexToken][classList.indexOf(c)] = (double) (freqToken + 1)\n",
    "\t\t\t\t\t\t\t\t\t/ (size + vocab.size());\n",
    "\t\t\t\t\t\t\tlogToken = Math.log(condProbArray[indexToken][classList.indexOf(c)]);\n",
    "\t\t\t\t\t\t\tscore[i] += logToken;\n",
    "\t\t\t\t\t\t\ti++;\n",
    "\t\t\t\t\t\t\tcontinue;\n",
    "\t\t\t\t\t\t}\n",
    "\t\t\t\t\t}\n",
    "\n",
    "\t\t\t\t\t// here if token is not in vocab then freq would be zero.\n",
    "\n",
    "\t\t\t\t\t// use this freq for condProbArray\n",
    "\t\t\t\t\telse {\n",
    "\n",
    "\t\t\t\t\t\tcondProb = (double) (freqToken + 1) / (size + vocab.size());\n",
    "\t\t\t\t\t\tlogToken = Math.log(condProb);\n",
    "\t\t\t\t\t\tscore[i] += logToken;\n",
    "\t\t\t\t\t\ti++;\n",
    "\t\t\t\t\t\tcontinue;\n",
    "\t\t\t\t\t}\n",
    "\t\t\t\t}\n",
    "\n",
    "\t\t\t}\n",
    "\n",
    "\t\t}\n",
    "\n",
    "\t\tfor (int i = 0; i < score.length; i++) {\n",
    "\t\t\tscore[i] += Math.log(priorProbs[i]);\n",
    "\t\t}\n",
    "\n",
    "\t\tdouble maxScore = score[0];\n",
    "\t\tint indexMax = 0;\n",
    "\t\tfor (int i = 1; i < score.length; i++) {\n",
    "\n",
    "\t\t\tif (score[i] > maxScore) {\n",
    "\t\t\t\tmaxScore = score[i];\n",
    "\t\t\t\tindexMax = i;\n",
    "\t\t\t}\n",
    "\n",
    "\t\t}\n",
    "\t\treturn classList.get(indexMax);\n",
    "\t}\n",
    "\n",
    "\t/**\n",
    "\t * Classifies the given document and returns the class name.\n",
    "\t */\n",
    "\tpublic String classify(String text) {\n",
    "\t\tString clazz = null;\n",
    "\n",
    "\t\tclazz = preprocessing(text);\n",
    "\n",
    "\t\t// YOUR CODE HERE\n",
    "\t\treturn clazz;\n",
    "\t}\n",
    "}\n",
    "\n",
    "/**\n",
    " * Learner (or Builder) class for a naive Bayes classifier.\n",
    " */\n",
    "class BayesianLearner {\n",
    "\t// YOUR CODE HERE\n",
    "\tList<String> vocab = new ArrayList();\n",
    "\tint N_docs = 0;\n",
    "\tMap<String, String> classText = new HashMap<>();\n",
    "\n",
    "\tList<String> classList = new ArrayList<>();\n",
    "\tList<Integer> Nclass = new ArrayList<>();\n",
    "\n",
    "\t/**\n",
    "\t * Constructor taking the set of classes the classifier should be able to\n",
    "\t * distinguish.\n",
    "\t */\n",
    "\tpublic BayesianLearner(Set<String> classes) {\n",
    "\t\t/*\n",
    "\t\t * in classlist, we store each class at an index. Thus we can count no.\n",
    "\t\t * of documents in the preprocessing step only.\n",
    "\t\t */\n",
    "\t\tfor (String clas : classes) {\n",
    "\t\t\tclassList.add(clas);\n",
    "\t\t\tNclass.add(0);\n",
    "\t\t}\n",
    "\n",
    "\t}\n",
    "\n",
    "\tString[] stopwords = { \"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\",\n",
    "\t\t\t\"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\",\n",
    "\t\t\t\"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\",\n",
    "\t\t\t\"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\",\n",
    "\t\t\t\"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\",\n",
    "\t\t\t\"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\",\n",
    "\t\t\t\"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\",\n",
    "\t\t\t\"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\",\n",
    "\t\t\t\"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\",\n",
    "\t\t\t\"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\" };\n",
    "\n",
    "\tList<String> stopWordsList = Arrays.asList(stopwords);\n",
    "\n",
    "\t/*\n",
    "\t * This method will update a map with the key being class and value being a\n",
    "\t * vector with term frequency. The size of vector is equal to vacab size\n",
    "\t */\n",
    "\tpublic void preprocessing(String clazz, String text) {\n",
    "\t\t// First a term from text is added to vocab. Now tempVect will represent\n",
    "\t\t// the text in numerical form. So, add 1 to the vector too. 1 is set to\n",
    "\t\t// index wrt vocab.\n",
    "\t\t// List<Integer> tempVect = new ArrayList<Integer>();\n",
    "\t\tString tempVect = new String();\n",
    "\t\tif (classText.containsKey(clazz)) {\n",
    "\t\t\ttempVect = classText.get(clazz);\n",
    "\t\t}\n",
    "\n",
    "\t\t// String[] tokens = text.toLowerCase().replaceAll(\"[^ a-zA-Z0-9]\",\n",
    "\t\t// \"\").split(\" \");\n",
    "\t\t// Performance measure test with the preprocessed textual content\n",
    "\t\tString text_processed = text.toLowerCase().replaceAll(\"[^ a-zA-Z0-9]\", \"\");\n",
    "\n",
    "\t\t// Performance measure: test with unprocessed textual content so that\n",
    "\t\t// term freq. has real textual count.\n",
    "\t\tString text_unprocessed = text;\n",
    "\n",
    "\t\tclassText.put(clazz, tempVect.concat(text_processed));\n",
    "\n",
    "\t}\n",
    "\n",
    "\tList<String> vocab1 = new ArrayList<>();\n",
    "\n",
    "\tvoid addVocab(String text) {\n",
    "\t\tString tokens[] = text.split(\" \");\n",
    "\t\tfor (String token : tokens) {\n",
    "\t\t\tif (!stopWordsList.contains(token)) {\n",
    "\t\t\t\tif (!vocab1.contains(token)) {\n",
    "\t\t\t\t\tvocab1.add(token);\n",
    "\t\t\t\t}\n",
    "\t\t\t}\n",
    "\t\t}\n",
    "\t}\n",
    "\n",
    "\t/**\n",
    "\t * The method used to learn the training examples. It takes the name of the\n",
    "\t * class as well as the text of the training document.\n",
    "\t */\n",
    "\tpublic void learnExample(String clazz, String text) {\n",
    "\t\t// YOUR CODE HERE\n",
    "\t\tint index = classList.indexOf(clazz);\n",
    "\t\tint count = 0;\n",
    "\t\t// NClass refer to the number of documents for a class(i) at index i.\n",
    "\t\tif (Nclass.size() <= index) {\n",
    "\t\t\tNclass.set(index, 1);\n",
    "\t\t} else {\n",
    "\t\t\tcount = Nclass.get(index) + 1;\n",
    "\t\t\tNclass.set(index, count);\n",
    "\t\t}\n",
    "\n",
    "\t\t// updates the count of documents for total\n",
    "\t\tN_docs++;\n",
    "\n",
    "\t\tpreprocessing(clazz, text);\n",
    "\n",
    "\t}\n",
    "\n",
    "\tMap<String, int[]> classFreqMap = new HashMap<>();\n",
    "\tMap<String, Integer> docSizeClass = new HashMap<>();\n",
    "\t\n",
    "\tvoid prepareArray(String text, String clazz) {\n",
    "\t\tString[] tokens = text.split(\" \");\n",
    "\t\tint size = tokens.length;\n",
    "//\t\tdocSizeClass.put(clazz, size);\n",
    "\t\tint[] wordArray = new int[vocab1.size()];\n",
    "\t\tint sum=0;\n",
    "\t\tfor (String token : tokens) {\n",
    "\t\t\t// check if the token is not in stop word\n",
    "\t\t\tif (!stopWordsList.contains(token)) {\n",
    "\t\t\t\t// find the index of token\n",
    "\t\t\t\tint indexToken = vocab1.indexOf(token);\n",
    "\t\t\t\t// add this token to the count present in the array at the index\n",
    "\t\t\t\t// of Vocab\n",
    "\t\t\t\twordArray[indexToken] += 1;\n",
    "\t\t\t\tsum++;\n",
    "\t\t\t}\n",
    "\t\t}\n",
    "\t\tdocSizeClass.put(clazz, sum);\n",
    "\t\t// store the class and word freq array to the map.\n",
    "\t\tclassFreqMap.put(clazz, wordArray);\n",
    "\t}\n",
    "\n",
    "\t/**\n",
    "\t * Creates a BayesianClassifier instance based on the statistics gathered\n",
    "\t * from the training example.\n",
    "\t */\n",
    "\n",
    "\tpublic BayesianClassifier createClassifier() {\n",
    "\n",
    "\t\t/*\n",
    "\t\t * Now conditional prob. is needed to be calculated.\n",
    "\t\t * :=(freq(term->V,class:c)+1)/(length(text,class:c)+V.length)\n",
    "\t\t */\n",
    "\t\tfor (String clazz : classText.keySet()) {\n",
    "\t\t\tString text = classText.get(clazz);\n",
    "\t\t\t// prepare the vocab list by iterating each class\n",
    "\t\t\taddVocab(text);\n",
    "\t\t}\n",
    "\n",
    "\t\t// for each class, prepare a new array with tokens from the list and\n",
    "\t\t// store into a new map.\n",
    "\t\t// right now our text is already preprocessed.\n",
    "\t\t\n",
    "\t\tfor (String clazz : classText.keySet()) {\n",
    "\t\t\tString text = classText.get(clazz);\n",
    "\t\t\t// prepare the vocab list by iterating each class\n",
    "\t\t\tprepareArray(text, clazz);\n",
    "\t\t}\n",
    "\t\t\n",
    "\n",
    "\t\tBayesianClassifier classifier = new BayesianClassifier(vocab1, N_docs, Nclass, classFreqMap, classList,docSizeClass);\n",
    "\n",
    "\t\t// YOUR CODE HERE\n",
    "\t\treturn classifier;\n",
    "\t}\n",
    "}\n",
    "// This line should make sure that compile errors are directly identified when\n",
    "// executing this cell\n",
    "// (the line itself does not produce any meaningful result)\n",
    "new BayesianLearner(new HashSet<>(Arrays.asList(\"good\",\"bad\")));\n",
    "System.out.println(\"compiled\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4e9c819c081918a6fde3b4ba21898440",
     "grade": false,
     "grade_id": "cell-markdown-evaluation",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Evaluation\n",
    "\n",
    "- Run the following cell to test your implementation.\n",
    "- You can ignore the cells afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "945ef53744e1c4ba8917ed6eebef6e52",
     "grade": true,
     "grade_id": "cell-autograde-visible",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Simple example corpus ----------\n",
      "Training corpus size: 5\n",
      "Eval. corpus size   : 3\n",
      "Training took       : 1ms\n",
      "Classification took : 0ms\n",
      "Baseline classifiers: \n",
      "Always literature   : 0.33333\n",
      "Always chess        : 0.33333\n",
      "Always history      : 0.33333\n",
      "Random guesser      : 0.33333\n",
      "Your solution       : 1.00000 (3 tp, 0 errors)\n",
      "Test successfully completed.\n",
      "\n",
      "---------- Larger example corpus ----------\n",
      "Training corpus size: 750\n",
      "Eval. corpus size   : 260\n",
      "Training took       : 4039ms\n",
      "Classification took : 1270ms\n",
      "Baseline classifiers: \n",
      "Always gold         : 0.03462\n",
      "Always money-fx     : 0.19231\n",
      "Always trade        : 0.16923\n",
      "Always interest     : 0.11538\n",
      "Always coffee       : 0.06154\n",
      "Always money-supply : 0.10000\n",
      "Always ship         : 0.05000\n",
      "Always sugar        : 0.06538\n",
      "Always crude        : 0.21154\n",
      "Random guesser      : 0.11111\n",
      "Your solution       : 0.85385 (222 tp, 38 errors)\n",
      "  Wrong classifications are:\n",
      "    id=5 expected=money-fx result=interest\n",
      "    id=10 expected=money-supply result=interest\n",
      "    id=27 expected=trade result=money-fx\n",
      "    id=39 expected=trade result=money-fx\n",
      "    id=43 expected=ship result=crude\n",
      "    id=46 expected=money-fx result=trade\n",
      "    id=55 expected=ship result=crude\n",
      "    id=56 expected=money-fx result=interest\n",
      "    id=62 expected=ship result=trade\n",
      "    id=70 expected=interest result=money-fx\n",
      "    id=78 expected=trade result=money-supply\n",
      "    id=90 expected=ship result=coffee\n",
      "    id=96 expected=money-fx result=interest\n",
      "    id=112 expected=gold result=interest\n",
      "    id=114 expected=money-fx result=interest\n",
      "    id=132 expected=money-fx result=interest\n",
      "    id=140 expected=money-supply result=interest\n",
      "    id=153 expected=ship result=crude\n",
      "    id=160 expected=coffee result=trade\n",
      "    id=173 expected=ship result=crude\n",
      "    ...\n",
      "Test successfully completed.\n"
     ]
    }
   ],
   "source": [
    "%maven org.junit.jupiter:junit-jupiter-api:5.3.1\n",
    "%maven commons-io:commons-io:2.6\n",
    "import org.junit.jupiter.api.Assertions;\n",
    "import org.opentest4j.AssertionFailedError;\n",
    "import java.util.stream.Collectors;\n",
    "import org.apache.commons.io.FileUtils;\n",
    "import java.util.Map.Entry;\n",
    "\n",
    "/**\n",
    " * Simple method for reading classification examples from a file as a list of (class, text) pairs.\n",
    " */\n",
    "public static List<String[]> readClassData(String filename) throws IOException {\n",
    "    return FileUtils.readLines(new File(filename), \"utf-8\").stream().map(s -> s.split(\"\\t\"))\n",
    "            .filter(s -> s.length > 1).collect(Collectors.toList());\n",
    "}\n",
    "\n",
    "/**\n",
    " * Method for cecking the given classifier. The method expects training and evaluation data.\n",
    " * The data should have a String array for each document in which the first cell of the\n",
    " * array contains the class while the second cell contains the text of the document. During\n",
    " * the check, some statistics like the accuracies of different baseline classifiers are\n",
    " * printed. Finally, the calculated accuracy is returned.\n",
    " *\n",
    " * @param trainingCorpus the data that is used for training the classifier. \n",
    " * @param evaluationCorpus the data that is used for evaluating the classifier. \n",
    " * @param minAccuracy minimum accuracy the classifier should achieve.\n",
    " * @return the accuracy achieved by the classifier\n",
    " */\n",
    "public static double checkClassifier(List<String[]> trainingCorpus, List<String[]> evaluationCorpus,\n",
    "        double minAccuracy) {\n",
    "    double accuracy = 0;\n",
    "    try {\n",
    "        System.out.print(\"Training corpus size: \");\n",
    "        System.out.println(trainingCorpus.size());\n",
    "        System.out.print(\"Eval. corpus size   : \");\n",
    "        System.out.println(evaluationCorpus.size());\n",
    "        // Determine the classes\n",
    "        Set<String> classes = Arrays.asList(trainingCorpus, evaluationCorpus).stream().flatMap(l -> l.stream())\n",
    "                .map(d -> d[0]).distinct().collect(Collectors.toSet());\n",
    "        // Determine the number of instances per class in the evaluation set\n",
    "        Map<String, Long> evalClassCounts = evaluationCorpus.stream()\n",
    "                .collect(Collectors.groupingBy(d -> d[0], Collectors.counting()));\n",
    "        for (String clazz : classes) {\n",
    "            if (!evalClassCounts.containsKey(clazz)) {\n",
    "                evalClassCounts.put(clazz, 0L);\n",
    "            }\n",
    "        }\n",
    "\n",
    "        // Determine the expected accuracies of the baselines\n",
    "        Map<String, Double> accForClassGuessers = new HashMap<>();\n",
    "        for (Entry<String, Long> e : evalClassCounts.entrySet()) {\n",
    "            accForClassGuessers.put(e.getKey(), e.getValue() / (double) evaluationCorpus.size());\n",
    "        }\n",
    "        double accRandomGuesser = 1.0 / accForClassGuessers.size();\n",
    "\n",
    "        // Train the classifier\n",
    "        long time1 = System.currentTimeMillis();\n",
    "        BayesianLearner learner = new BayesianLearner(classes);\n",
    "        for (String[] trainingExample : trainingCorpus) {\n",
    "            learner.learnExample(trainingExample[0], trainingExample[1]);\n",
    "        }\n",
    "        BayesianClassifier classifier = learner.createClassifier();\n",
    "        time1 = System.currentTimeMillis() - time1;\n",
    "        System.out.println(\"Training took       : \" + time1 + \"ms\");\n",
    "\n",
    "        // Classify the evaluation corpus\n",
    "        long time2 = System.currentTimeMillis();\n",
    "        int tp = 0, errors = 0, id = 0;\n",
    "        String result;\n",
    "        List<String[]> fpDetails = new ArrayList<>();\n",
    "        for (String[] evalExample : evaluationCorpus) {\n",
    "            result = classifier.classify(evalExample[1]);\n",
    "            if (evalExample[0].equals(result)) {\n",
    "                ++tp;\n",
    "            } else {\n",
    "                ++errors;\n",
    "                fpDetails.add(new String[] { Integer.toString(id), evalExample[0], result });\n",
    "            }\n",
    "            ++id;\n",
    "        }\n",
    "        time2 = System.currentTimeMillis() - time2;\n",
    "        System.out.println(\"Classification took : \" + time2 + \"ms\");\n",
    "        accuracy = tp / (double) (tp + errors);\n",
    "\n",
    "        System.out.println(\"Baseline classifiers: \");\n",
    "        for (Entry<String, Double> baseResult : accForClassGuessers.entrySet()) {\n",
    "            System.out.println(String.format(\"Always %-13s: %-7.5f\", baseResult.getKey(), baseResult.getValue()));\n",
    "        }\n",
    "        System.out.println(String.format(\"Random guesser      : %-7.5f\", accRandomGuesser));\n",
    "        System.out.println(String.format(\"Your solution       : %-7.5f (%d tp, %d errors)\", accuracy, tp, errors));\n",
    "        if (fpDetails.size() > 0) {\n",
    "            System.out.println(\"  Wrong classifications are:\");\n",
    "            for (int i = 0; i < Math.min(fpDetails.size(), 20); ++i) {\n",
    "                System.out.print(\"    id=\");\n",
    "                System.out.print(fpDetails.get(i)[0]);\n",
    "                System.out.print(\" expected=\");\n",
    "                System.out.print(fpDetails.get(i)[1]);\n",
    "                System.out.print(\" result=\");\n",
    "                System.out.println(fpDetails.get(i)[2]);\n",
    "            }\n",
    "            if (fpDetails.size() > 20) {\n",
    "                System.out.println(\"    ...\");\n",
    "            }\n",
    "        }\n",
    "\n",
    "        // Make sure that the students solution is better than all baselines\n",
    "        for (Entry<String, Double> baseResult : accForClassGuessers.entrySet()) {\n",
    "            if (baseResult.getValue() >= accuracy) {\n",
    "                StringBuilder builder = new StringBuilder();\n",
    "                builder.append(\"Your solution is not better than a classifier that always chooses the \\\"\");\n",
    "                builder.append(baseResult.getKey());\n",
    "                builder.append(\"\\\" class.\");\n",
    "                Assertions.fail(builder.toString());\n",
    "            }\n",
    "        }\n",
    "        if (accRandomGuesser >= accuracy) {\n",
    "            Assertions.fail(\"Your solution is not better than a random guesser.\");\n",
    "        }\n",
    "        if ((minAccuracy > 0) && (minAccuracy > accuracy)) {\n",
    "            Assertions.fail(\"Your solution did not reach the expected accuracy of \" + minAccuracy);\n",
    "        }\n",
    "        System.out.println(\"Test successfully completed.\");\n",
    "    } catch (AssertionFailedError e) {\n",
    "        throw e;\n",
    "    } catch (Throwable e) {\n",
    "        System.err.println(\"Your solution caused an unexpected error:\");\n",
    "        throw e;\n",
    "    }\n",
    "    return accuracy;\n",
    "}\n",
    "\n",
    "/*\n",
    " * Test case 1: a simple example corpus which is easy to do by hand.\n",
    " */\n",
    "System.out.println(\"---------- Simple example corpus ----------\");\n",
    "List<String[]> exampleCorpusTrain = Arrays.asList(\n",
    "        new String[] {\"chess\", \"white king, black rook, black queen, white pawn, black knight, white bishop.\" },\n",
    "        new String[] {\"history\", \"knight person granted honorary title knighthood\" },\n",
    "        new String[] {\"history\", \"knight order eligibility, knighthood, head of state, king, prelate, middle ages.\" },\n",
    "        new String[] {\"chess\", \"Defense knight pawn opening game opponent.\" },\n",
    "        new String[] {\"literature\", \"Knights Round Table. King Arthur. literary cycle Matter of Britain.\"}\n",
    "        );\n",
    "List<String[]> exampleCorpusTest = Arrays.asList(\n",
    "        new String[] {\"history\", \"Knighthood Middle Ages.\" },\n",
    "        new String[] {\"chess\", \"player king knight opponent king checkmate game draw.\" },\n",
    "        // document with unknown words\n",
    "        new String[] {\"literature\", \"britain king arthur. Sir Galahad.\" }\n",
    "        );\n",
    "\n",
    "double accuracy = checkClassifier(exampleCorpusTrain, exampleCorpusTest, 0);\n",
    "\n",
    "\n",
    "/*\n",
    " * Test case 2: a more complex example on real-world data.\n",
    " */\n",
    "System.out.println();\n",
    "System.out.println(\"---------- Larger example corpus ----------\");\n",
    "List<String[]> classificationData =readClassData(\"/srv/distribution/single-class-train.tsv\");\n",
    "accuracy = checkClassifier(classificationData.subList(0, 750), classificationData.subList(750, classificationData.size()), 0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fc4723f8815725c44713410c8d9ce586",
     "grade": true,
     "grade_id": "cell-autograde-1",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "// Ignore this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2280a65ff154fb7d12936e76235be051",
     "grade": true,
     "grade_id": "cell-autograde-2",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "// Ignore this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0ba1b93c7dc47996a5c81821c0c7c5cd",
     "grade": true,
     "grade_id": "cell-autograde-3",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "// Ignore this cell"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Java",
   "language": "java",
   "name": "java"
  },
  "language_info": {
   "codemirror_mode": "java",
   "file_extension": ".jshell",
   "mimetype": "text/x-java-source",
   "name": "Java",
   "pygments_lexer": "java",
   "version": "11.0.4+11-post-Ubuntu-1ubuntu218.04.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
